#!/usr/bin/env python3

from pathlib import Path
import pandas
import logging
import shutil


#############
# FUNCTIONS #
#############

def aggregate_regions(wildcards):
    co = checkpoints.generate_regions.get(**wildcards).output['region']
    r = glob_wildcards(Path(co, 'r{region}')).region
    return expand(Path(calldir, 'regions', 'r{region}.vcf').as_posix(),
                  region=r)


def resolve_raw_fastq(wildcards):
    return({
        'r1': sample_data.loc[wildcards.sample_name, 'r1_path'],
        'r2': sample_data.loc[wildcards.sample_name, 'r2_path']
        })


def resolve_path(x):
    return str(Path(x).resolve())


###########
# GLOBALS #
###########

# get config
# configfile: 'config.yaml' # get path from entry point
ref = config['ref']
outdir = config['outdir']
max_threads = config['threads']
samples_csv = config['samples_csv']

# set up directories
logdir = Path(outdir, 'logs')
statdir = Path(outdir, 'stats')
tmpdir = Path(outdir, 'tmp')
trimdir = Path(outdir, '010_trim')
mapdir = Path(outdir, '020_map')
calldir = Path(outdir, '030_calls')

# for filtering and trimming
bbduk_ref = '/phix174_ill.ref.fa.gz'
bbduk_adaptors = '/adapters.fa'

# dict of extensions and arguments for vcftools
ext_to_arg = {
    'frq': 'freq2 --max-alleles 2',
    'idepth': 'depth',
    'ldepth.mean': 'site-mean-depth',
    'lqual': 'site-quality',
    'imiss': 'missing-indv',
    'lmiss': 'missing-site'}


########
# MAIN #
########

# what got passed
logging.debug(f'Snakefile config\n{config}')

# get a list of individuals from the csv
sample_data = pandas.read_csv(samples_csv,
                              index_col='sample')
all_samples = sorted(set(sample_data.index))
logging.debug(f'All samples:\n{all_samples}')

# freebayes ploidy
if config['cnv_map']:
    cnv_map = config['cnv_map']
    ploidy_line = f'--cnv-map {cnv_map} --pooled-discrete '
else:
    ploidy = config['ploidy']
    ploidy_line = f'--ploidy {ploidy} '
logging.debug(f'ploidy_line\n{ploidy_line}')

# list of snakemake targets
target_list = [
    Path(outdir, 'calls.vcf.gz'),
    Path(outdir, 'calls.vcf.gz.tbi'),
    Path(outdir, 'merged.bam'),
    Path(outdir, 'merged.bam.bai'),
    Path(outdir, '040_stats', 'ldepth.mean_cutoffs.csv'),
    expand(Path(outdir, '050_plots', '{ext}.pdf').as_posix(),
           ext=list(ext_to_arg.keys())),
    Path(outdir, '015_ref', 'ref.fasta'),
    Path(outdir, '015_ref', 'ref.fasta.fai'),
    expand(Path(mapdir, '{sample_name}.bam.bai').as_posix(),
           sample_name=all_samples),
    expand(Path(mapdir, '{sample_name}.ihist').as_posix(),
           sample_name=all_samples),
    Path(outdir, '050_plots', 'insert_size_histograms.pdf')]

if config['csd']:
    target_list.append(Path(outdir, 'csd.vcf.gz'))


#########
# RULES #
#########

rule target:
    input:
        target_list

rule calculate_ldepth_cutoff:
    input:
        stats = Path(outdir, '040_stats', 'stats.ldepth.mean')
    output:
        csv = Path(outdir, '040_stats', 'ldepth.mean_cutoffs.csv')
    log:
        Path(logdir, 'calculate_ldepth_cutoff.log')
    script:
        shutil.which('calculate_ldepth_cutoff.R')

rule plot_stats:
    input:
        Path(outdir, '040_stats', 'stats.{ext}')
    output:
        Path(outdir, '050_plots', '{ext}.pdf')
    log:
        Path(logdir, 'plot_{ext}.log')
    shell:
        'plot_{wildcards.ext}.R '
        '{input} '
        '{output} '
        '&> {log}'


##################################
# VAR CALLING AND VCF PROCESSING #
##################################

rule vcf_stats:
    input:
        Path(outdir, 'calls.vcf.gz')
    output:
        Path(outdir, '040_stats', 'stats.{ext}')
    log:
        Path(logdir, 'stats_{ext}.log')
    params:
        wd = Path(outdir, '040_stats'),
        arg = lambda wildcards: ext_to_arg[wildcards.ext]
    shell:
        'cd {params.wd} || exit 1 ; '
        'vcftools '
        '--gzvcf '
        + resolve_path('{input}') + ' '
        '--{params.arg} '
        '--out stats '
        '2> ' + resolve_path('{log}')

rule vcfuniq:
    input:
        Path(tmpdir, 'all_sort.vcf')
    output:
        Path(outdir, 'calls.vcf')
    shell:
        'vcfuniq < {input} > {output}'

rule vcfstreamsort:
    input:
        Path(tmpdir, 'all_oneheader.vcf')
    output:
        temp(Path(tmpdir, 'all_sort.vcf'))
    shell:
        'vcfstreamsort -w 1000 < {input} >> {output}'

rule vcffirstheader:
    input:
        Path(tmpdir, 'all.vcf')
    output:
        temp(Path(tmpdir, 'all_oneheader.vcf'))
    shell:
        'vcffirstheader < {input} >> {output}'

rule combine_vcf:
    input:
        aggregate_regions
    output:
        temp(Path(tmpdir, 'all.vcf'))
    script:
        shutil.which('combine_vcf.py')

rule freebayes:
    input:
        bam = expand(Path(mapdir, '{sample_name}.bam').as_posix(),
                     sample_name=all_samples),
        bai = expand(Path(mapdir, '{sample_name}.bam.bai').as_posix(),
                     sample_name=all_samples),
        region = Path(outdir, '015_ref', 'regions', 'r{region}'),
        fa = Path(outdir, '015_ref', 'ref.fasta')
    output:
        vcf = Path(calldir, 'regions', 'r{region}.vcf')
    log:
        Path(logdir, 'r{region}_freebayes.log')
    shell:
        'freebayes '
        '--region  "$(cat {input.region})" '
        '{ploidy_line} '
        '--use-best-n-alleles 4 '
        '-f {input.fa} '
        '{input.bam} '
        '> {output} '
        '2> {log}'

rule freebayes_csd:
    input:
        bam = expand(Path(mapdir, '{sample_name}.bam').as_posix(),
                     sample_name=all_samples),
        bai = expand(Path(mapdir, '{sample_name}.bam.bai').as_posix(),
                     sample_name=all_samples),
        fa = Path(outdir, '015_ref', 'ref.fasta')
    output:
        vcf = Path(outdir, 'csd.vcf')
    params:
        csd = 'NC_037640.1:11771679-11781139'
    log:
        Path(logdir, 'freebayes_csd.log')
    shell:
        'freebayes '
        '--region  {params.csd} '
        '{ploidy_line} '
        '-f {input.fa} '
        '{input.bam} '
        '> {output} '
        '2> {log}'

checkpoint generate_regions:
    input:
        fai = Path(outdir, '015_ref', 'ref.fasta.fai')
    output:
        region = directory(Path(outdir, '015_ref', 'regions'))
    params:
        prefix = Path(outdir, '015_ref', 'regions', 'r')
    shell:
        'mkdir {output.region} ; '
        'awk '
        '\'{{printf("%s:1-%d\\n",$1,$2);}}\' '
        '{input} '
        '| '
        'split '
        '-a 4 '
        '-l 1 '
        '-d '
        '- '
        '{params.prefix}'


##############################
# MAPPING AND BAM PROCESSING #
##############################

# for visualisation
rule merge_bam:
    input:
        bam = expand(Path(mapdir, '{sample_name}.bam').as_posix(),
                     sample_name=all_samples),
    output:
        Path(outdir, 'merged.bam')
    log:
        Path(logdir, 'merge_bam.log')
    threads:
        min(20, max_threads)
    shell:
        'samtools merge '
        '-l 9 '
        '-O BAM '
        '-@ {threads} '
        '{output} '
        '{input.bam} '
        '2> {log}'

rule plot_ihist:
    input:
        ihist_files = expand(Path(mapdir, '{sample_name}.ihist').as_posix(),
                             sample_name=all_samples)
    output:
        plot = Path(outdir, '050_plots', 'insert_size_histograms.pdf')
    log:
        Path(logdir, 'plot_ihist.log')
    script:
        shutil.which('plot_ihist.R')

rule ihist:
    input:
        Path(mapdir, '{sample_name}.bam')
    output:
        Path(mapdir, '{sample_name}.ihist')
    log:
        Path(logdir, 'ihist.{sample_name}.log')
    shell:
        'reformat.sh '
        'in={input} '
        'out=/dev/null '
        'ihist={output} '
        'mappedonly=t '
        'pairedonly=t '
        'primaryonly=t '
        'filterbits=1024 '
        '2> {log}'

rule markdup:
    input:
        Path(tmpdir, '{sample_name}_sort.bam')
    output:
        Path(mapdir, '{sample_name}.bam')
    log:
        Path(logdir, '{sample_name}_markdup.log')
    shell:
        'samtools markdup '
        f'-@ {max_threads // 3} '
        '-s '
        '{input} '
        '{output} '
        '2> {log}'

rule sort:
    input:
        Path(tmpdir, '{sample_name}_fixmate.bam')
    output:
        pipe(Path(tmpdir, '{sample_name}_sort.bam'))
    log:
        Path(logdir, '{sample_name}_sort.log')
    shell:
        'samtools sort '
        f'-@ {max_threads // 3} '
        '{input} '
        '>> {output} '
        '2> {log}'

rule fixmate:
    input:
        Path(tmpdir, '{sample_name}.sam')
    output:
        pipe(Path(tmpdir, '{sample_name}_fixmate.bam'))
    log:
        Path(logdir, '{sample_name}_fixmate.log')
    shell:
        'samtools fixmate '
        '-m '
        f'-@ {max_threads // 3} '
        '{input} '
        '- '
        '>> {output} '
        '2> {log}'

rule bwa_map:
    input:
        fq = Path(trimdir, '{sample_name}.fastq'),
        index = expand(
            Path(outdir, '015_ref', 'ref.fasta.{suffix}').as_posix(),
            suffix=['amb', 'ann', 'bwt', 'pac', 'sa'])
    output:
        temp(Path(tmpdir, '{sample_name}.sam'))
    params:
        prefix = Path(outdir, '015_ref', 'ref.fasta'),
        rg = '\'@RG\\tID:{sample_name}\\tSM:{sample_name}\''
    threads:
        max(max_threads - 3, 1)
    log:
        Path(logdir, '{sample_name}_bwa-map.log')
    shell:
        'bwa mem '
        f'-t {max_threads} '
        '-p '
        '-R {params.rg} '
        '{params.prefix} '
        '{input.fq} '
        '> {output} '
        '2> {log}'

rule bwa_index:
    input:
        ref
    output:
        expand(Path(outdir, '015_ref', 'ref.fasta.{suffix}').as_posix(),
               suffix=['amb', 'ann', 'bwt', 'pac', 'sa'])
    params:
        prefix = Path(outdir, '015_ref', 'ref.fasta')
    log:
        Path(logdir, 'bwa_index.log')
    shell:
        'bwa index '
        '-p {params.prefix} '
        '{input} '
        '2> {log}'


#######################
# RAW READ PROCESSING #
#######################

rule trim:
    input:
        Path(tmpdir, '{sample_name}_filter.fastq')
    output:
        fastq = Path(trimdir, '{sample_name}.fastq'),
        stats = Path(statdir, '{sample_name}_trim.txt')
    log:
        Path(logdir, '{sample_name}_trim.log')
    params:
        trim = bbduk_adaptors
    shell:
        'bbduk.sh '
        'in={input} '
        'int=t '
        'out={output.fastq} '
        'ref={params.trim} '
        'ktrim=r k=23 mink=11 hdist=1 tpe tbo '
        'forcetrimmod=5 '
        'stats={output.stats} '
        '2> {log}'

rule filter:
    input:
        Path(tmpdir, '{sample_name}_check-barcodes.fastq')
    output:
        pipe = pipe(Path(tmpdir, '{sample_name}_filter.fastq')),
        stats = Path(statdir, '{sample_name}_filter.txt')
    log:
        Path(logdir, '{sample_name}_filter.log')
    params:
        filter = bbduk_ref,
    shell:
        'bbduk.sh '
        'in={input} '
        'int=t '
        'out=stdout.fastq '
        'ref={params.filter} '
        'hdist=1 '
        'stats={output.stats} '
        '>>{output.pipe} '
        '2> {log}'


rule check_barcodes:
    input:
        Path(tmpdir, '{sample_name}_repair.fastq')
    output:
        pipe = pipe(Path(tmpdir, '{sample_name}_check-barcodes.fastq'))
    params:
        barcode = lambda wildcards:
            sample_data.loc[wildcards.sample_name, 'barcode']
    log:
        Path(statdir, '{sample_name}_check-barcodes.txt')
    shell:
        'reformat.sh '
        'in={input} '
        'int=t '
        'out=stdout.fastq '
        'barcodefilter=t '
        'barcodes=\'{params.barcode}\' '
        '>> {output.pipe} '
        '2> {log}'

rule check_pairing:
    input:
        unpack(resolve_raw_fastq)
    output:
        pipe = pipe(Path(tmpdir, '{sample_name}_repair.fastq')),
    log:
        Path(statdir, '{sample_name}_repair.txt')
    shell:
        'repair.sh '
        'in={input.r1} '
        'in2={input.r2} '
        'out=stdout.fastq '
        '>> {output.pipe} '
        '2> {log}'


#################
# GENERIC RULES #
#################

# fasta index
rule fa_index:
    input:
        ref
    output:
        fa = Path(outdir, '015_ref', 'ref.fasta'),
        fai = Path(outdir, '015_ref', 'ref.fasta.fai')
    shell:
        'cp {input} {output.fa} '
        '; '
        'samtools faidx {output.fa}'

# vcf index
rule index_vcf:
    input:
        Path('{folder}', '{file}.vcf')
    output:
        gz = Path('{folder}', '{file}.vcf.gz'),
        tbi = Path('{folder}', '{file}.vcf.gz.tbi')
    log:
        Path(logdir, '{folder}', '{file}_index-vcf.log')
    shell:
        'bgzip -c {input} > {output.gz} 2> {log} '
        '; '
        'tabix -p vcf {output.gz} 2>> {log}'


# bamfile index
rule index_bamfile:
    input:
        Path('{folder}', '{file}.bam')
    output:
        Path('{folder}', '{file}.bam.bai')
    log:
        Path(logdir, '{folder}', '{file}_index-bamfile.log')
    threads:
        2
    shell:
        'samtools index -@ {threads} {input} 2> {log}'
